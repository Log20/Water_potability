{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCzhvs417SI0",
        "outputId": "923b89fe-5f2f-4812-e371-ad274628ad21"
      },
      "outputs": [],
      "source": [
        "# 填補空缺值\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"water_potability.csv\")\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(inplace=True)\n",
        "while (df[\"Potability\"] == 0).sum() != (df[\"Potability\"] == 1).sum():\n",
        "    # 找到第一個 0 的 index 並刪除\n",
        "    index_to_remove = df.index[df[\"Potability\"] == 0].tolist()[0]\n",
        "    df = df.drop(index_to_remove)\n",
        "\n",
        "df.drop(\"index\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZrT-mcpr7SIy",
        "outputId": "ac3b5c1e-1d86-4dba-9244-555fa228bf4a"
      },
      "outputs": [],
      "source": [
        "# 特徵分布分析\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "df.hist(figsize=(15, 15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "eYXdB4Op7SIz",
        "outputId": "bb89ada3-3c11-467e-d647-c6145a16801a"
      },
      "outputs": [],
      "source": [
        "# 分析特徵相依性\n",
        "# 正數為有正關聯，負數則為負關聯\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "corr = df.corr()\n",
        "corrMask = np.triu(corr)\n",
        "\n",
        "sns.heatmap(\n",
        "    corr,\n",
        "    linewidths=1,\n",
        "    annot=True,\n",
        "    square=True,\n",
        "    mask=corrMask,\n",
        "    cmap=\"Blues\",\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfdu6uSO7SI1"
      },
      "outputs": [],
      "source": [
        "# 切分特徵和目標變量\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop(\"Potability\", axis=1)\n",
        "y = df[\"Potability\"]\n",
        "# 切分訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "def grid_search_best_params(model_name):\n",
        "    \"\"\"\n",
        "    Perform GridSearchCV to find the best hyperparameters for a classifier.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Features for training.\n",
        "    - y_train: Target variable for training.\n",
        "    - model_name: Name of the model.\n",
        "\n",
        "    Returns:\n",
        "    - trained_model: The trained model with the best hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_model_with_params(model_name):\n",
        "        # Convert the model name to lowercase for case-insensitive matching\n",
        "        model_name_lower = model_name.lower()\n",
        "\n",
        "        models = {\n",
        "            \"decision tree\": DecisionTreeClassifier(),\n",
        "            \"random forest\": RandomForestClassifier(),\n",
        "            \"svm\": SVC(),\n",
        "            \"logistic regression\": LogisticRegression(),\n",
        "            \"bagging classifier\": BaggingClassifier(),\n",
        "            \"knn\": KNeighborsClassifier(),\n",
        "        }\n",
        "\n",
        "        # Use the lowercase model name for case-insensitive matching\n",
        "        return models.get(model_name_lower)\n",
        "\n",
        "    print(f\"Searching for best hyperparameters for {model_name}...\")\n",
        "\n",
        "    # Get the model instance\n",
        "    model = get_model_with_params(model_name)\n",
        "\n",
        "    if model is None:\n",
        "        print(f\"Model '{model_name}' not found.\")\n",
        "        return None\n",
        "\n",
        "    # Define hyperparameter grid for the specific model\n",
        "    param_grid = get_hyperparameter_grid(model_name)\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best hyperparameters\n",
        "    best_params = grid_search.best_params_\n",
        "\n",
        "    # Apply best hyperparameters to the model instance\n",
        "    model.set_params(**best_params)\n",
        "\n",
        "    # Train the model with the full training set\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
        "    print(\n",
        "        f\"Best cross-validation score for {model_name}: {grid_search.best_score_:.2f}\\n\"\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_hyperparameter_grid(model_name):\n",
        "    \"\"\"\n",
        "    Define hyperparameter grid for each model.\n",
        "    Modify this function to add more models and their respective hyperparameter grids.\n",
        "\n",
        "    Parameters:\n",
        "    - model_name: Name of the model.\n",
        "\n",
        "    Returns:\n",
        "    - param_grid: Hyperparameter grid for the specified model.\n",
        "    \"\"\"\n",
        "    param_grids = {\n",
        "        \"decision tree\": {\"max_depth\": [3, 5, 7], \"min_samples_split\": [2, 5, 10]},\n",
        "        \"random forest\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [None, 5, 10]},\n",
        "        \"svm\": {\n",
        "            \"C\": [1, 10, 100],\n",
        "            \"kernel\": [\"linear\", \"rbf\"],\n",
        "            \"gamma\": [\"scale\", \"auto\"],\n",
        "            \"probability\": [\"True\", \"False\"],\n",
        "        },\n",
        "        \"logistic regression\": {\n",
        "            \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
        "            \"penalty\": [\"l1\", \"l2\"],\n",
        "        },\n",
        "        \"bagging classifier\": {\"n_estimators\": [50, 100, 200]},\n",
        "        \"knn\": {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]},\n",
        "    }\n",
        "    return param_grids.get(model_name, {})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def evaluate_model(model):\n",
        "    \"\"\"\n",
        "    Train and evaluate a machine learning model, and display visualizations.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The machine learning model to be trained and evaluated.\n",
        "    - X_train, X_test: Features for training and testing.\n",
        "    - y_train, y_test: Target variable for training and testing.\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: Accuracy of the trained model on the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Display the classification report\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "    # Display the confusion matrix heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(\n",
        "        confusion_matrix(y_test, predictions),\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        cbar=False,\n",
        "        xticklabels=np.unique(y_test),\n",
        "        yticklabels=np.unique(y_test),\n",
        "    )\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    # Display feature importance or coefficients in a bar plot\n",
        "    if hasattr(model, \"feature_importances_\"):\n",
        "        plt.bar(X_train.columns, model.feature_importances_)\n",
        "        plt.xlabel(\"Features\")\n",
        "        plt.ylabel(\"Importance\")\n",
        "        plt.title(\"Feature Importance\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.show()\n",
        "    elif hasattr(model, \"coef_\"):\n",
        "        plt.bar(X_train.columns, model.coef_[0])\n",
        "        plt.xlabel(\"Features\")\n",
        "        plt.ylabel(\"Coefficient\")\n",
        "        plt.title(\"Feature Coefficients\")\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.show()\n",
        "\n",
        "    # Calculate and return accuracy\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have a model named 'your_model' and features 'X_train', 'X_test' with corresponding target variables 'y_train', 'y_test'\n",
        "# Replace 'your_model', 'X_train', 'X_test', 'y_train', 'y_test' with your actual model and data\n",
        "# accuracy = evaluate_model_with_visualizations(your_model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 決策樹\n",
        "# 對水質數據進行分類\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "# 建立決策樹模型\n",
        "dt = grid_search_best_params(\"Decision Tree\")\n",
        "dtAccuracy = evaluate_model(dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RandomForest\n",
        "# 創建一個隨機森林分類器\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "rf = grid_search_best_params(\"Random Forest\")\n",
        "rfAccuracy = evaluate_model(rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 邏輯回歸\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "lr = grid_search_best_params(\"Logistic Regression\")\n",
        "lrAccuracy = evaluate_model(lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# BaggingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "\n",
        "bagging = grid_search_best_params(\"Bagging Classifier\")\n",
        "baggingAccuracy = evaluate_model(bagging)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "\n",
        "def explain_model(model):\n",
        "    \"\"\"\n",
        "    Explain the predictions of a classifier using Permutation Importance.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The trained classifier model.\n",
        "    - X: Input data for explaining predictions.\n",
        "    - y: True labels for the data. Required for permutation importance. Default is None.\n",
        "\n",
        "    Returns:\n",
        "    - Importance scores (Permutation Importance).\n",
        "    \"\"\"\n",
        "\n",
        "    # Permutation Importance is used for any classifier\n",
        "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=0)\n",
        "    importance = result.importances_mean\n",
        "    plot_feature_importance(importance, X.columns)  # Plot the feature importance\n",
        "    return importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "f560gr-EYVas",
        "outputId": "cc49c718-a34d-4f9c-b23b-b7cd33d302d4"
      },
      "outputs": [],
      "source": [
        "# KNN\n",
        "\n",
        "# 特徵標準化\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = grid_search_best_params(\"KNN\")\n",
        "knnAccuracy = evaluate_model(knn)\n",
        "\n",
        "knn_explanation = explain_model(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVM\n",
        "# 初始化 SVM 分類器\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = grid_search_best_params(\"SVM\")\n",
        "svmAccuracy = evaluate_model(svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores = pd.DataFrame(\n",
        "    {\n",
        "        \"models\": [\n",
        "            \"Logistic Regression\",\n",
        "            \"Decision Tree\",\n",
        "            \"Random Forest\",\n",
        "            \"KNN\",\n",
        "            \"SVM\",\n",
        "            \"Bagging Classifier\",\n",
        "        ],\n",
        "        \"accuracy\": [\n",
        "            lrAccuracy,\n",
        "            dtAccuracy,\n",
        "            rfAccuracy,\n",
        "            knnAccuracy,\n",
        "            svmAccuracy,\n",
        "            baggingAccuracy,\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "scores.sort_values(by=[\"accuracy\"]).style.background_gradient(subset=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assume you have trained models: dt, rf, knn, svm, lr, bagging\n",
        "# Replace them with the actual trained models\n",
        "\n",
        "models = [\n",
        "    (\"dt\", dt),\n",
        "    (\"rf\", rf),\n",
        "    (\"knn\", knn),\n",
        "    (\"svm\", svm),\n",
        "    (\"lr\", lr),\n",
        "    (\"bagging\", bagging),\n",
        "]\n",
        "\n",
        "# Create a VotingClassifier using all base models\n",
        "voting_model = VotingClassifier(estimators=models, voting=\"hard\")\n",
        "\n",
        "voting_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Assuming you have test data X_test, y_test\n",
        "# Evaluate the VotingClassifier\n",
        "voting_predictions = voting_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, voting_predictions)\n",
        "print(f\"Voting Classifier Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Classification Report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, voting_predictions))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    confusion_matrix(y_test, voting_predictions),\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    xticklabels=[\"Not Potable\", \"Potable\"],\n",
        "    yticklabels=[\"Not Potable\", \"Potable\"],\n",
        ")\n",
        "plt.title(\"Voting Classifier Confusion Matrix\")\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Test Data\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
